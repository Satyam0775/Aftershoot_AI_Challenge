{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d93b76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active code page: 1252\n",
      "Requirement already satisfied: torch in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.24.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (11.3.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.6)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\satya\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\satya\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\satya\\appdata\\roaming\\python\\python310\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\satya\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\satya\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.12.0.88\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\satya\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision numpy pandas scikit-learn pillow tqdm matplotlib opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e3eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 1Ô∏è‚É£ Import Libraries\n",
    "# ========================================\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5a90a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train images path: C:\\Users\\satya\\Downloads\\Aftershoot_AI_Challenge\\task\\dataset\\Train\\images\n",
      "‚úÖ Validation images path: C:\\Users\\satya\\Downloads\\Aftershoot_AI_Challenge\\task\\dataset\\Validation\\images\n",
      "‚úÖ Train CSV path: C:\\Users\\satya\\Downloads\\Aftershoot_AI_Challenge\\task\\dataset\\Train\\sliders.csv\n",
      "‚úÖ Validation CSV path: C:\\Users\\satya\\Downloads\\Aftershoot_AI_Challenge\\task\\dataset\\Validation\\sliders_input.csv\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# ‚úÖ Correct Final Dataset Paths\n",
    "# ========================================\n",
    "BASE_DIR = r\"C:\\Users\\satya\\Downloads\\Aftershoot_AI_Challenge\\task\\dataset\"\n",
    "\n",
    "TRAIN_IMG_DIR = os.path.join(BASE_DIR, \"Train\", \"images\")\n",
    "VAL_IMG_DIR = os.path.join(BASE_DIR, \"Validation\", \"images\")\n",
    "\n",
    "TRAIN_CSV = os.path.join(BASE_DIR, \"Train\", \"sliders.csv\")\n",
    "VAL_CSV = os.path.join(BASE_DIR, \"Validation\", \"sliders_input.csv\")\n",
    "\n",
    "print(\"‚úÖ Train images path:\", TRAIN_IMG_DIR)\n",
    "print(\"‚úÖ Validation images path:\", VAL_IMG_DIR)\n",
    "print(\"‚úÖ Train CSV path:\", TRAIN_CSV)\n",
    "print(\"‚úÖ Validation CSV path:\", VAL_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "105bd979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images Found: True\n",
      "Validation Images Found: True\n",
      "Train CSV Found: True\n",
      "Validation CSV Found: True\n",
      "No. of train images: 2539\n",
      "No. of validation images: 493\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# üîç Verify Folder Existence\n",
    "# ========================================\n",
    "print(\"Train Images Found:\", os.path.exists(TRAIN_IMG_DIR))\n",
    "print(\"Validation Images Found:\", os.path.exists(VAL_IMG_DIR))\n",
    "print(\"Train CSV Found:\", os.path.exists(TRAIN_CSV))\n",
    "print(\"Validation CSV Found:\", os.path.exists(VAL_CSV))\n",
    "\n",
    "# Also print counts\n",
    "print(\"No. of train images:\", len(os.listdir(TRAIN_IMG_DIR)))\n",
    "print(\"No. of validation images:\", len(os.listdir(VAL_IMG_DIR)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee27a265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Columns in Train CSV:\n",
      " ['copyCreationTime', 'captureTime', 'touchTime', 'id_global', 'grayscale', 'aperture', 'flashFired', 'focalLength', 'isoSpeedRating', 'shutterSpeed', 'Temperature', 'Tint', 'currTemp', 'currTint']\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# üïµÔ∏è Step 1 ‚Äî Check available columns in your CSV\n",
    "# ========================================\n",
    "import pandas as pd\n",
    "\n",
    "check_train = pd.read_csv(TRAIN_CSV)\n",
    "print(\"Available Columns in Train CSV:\\n\", list(check_train.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aafa9c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Preprocessing successful!\n",
      "Train shape: (2538, 14)\n",
      "Val shape: (493, 12)\n",
      "Numeric columns used: ['grayscale', 'aperture', 'flashFired', 'focalLength', 'isoSpeedRating', 'shutterSpeed', 'currTemp', 'currTint']\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Load and Preprocess Metadata\n",
    "# ========================================\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load CSVs\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "val_df = pd.read_csv(VAL_CSV)\n",
    "\n",
    "# Define columns\n",
    "numeric_cols = [\n",
    "    'grayscale', 'aperture', 'flashFired', \n",
    "    'focalLength', 'isoSpeedRating', 'shutterSpeed', \n",
    "    'currTemp', 'currTint'\n",
    "]\n",
    "categorical_cols = []  # none in your dataset\n",
    "\n",
    "# Fill missing numeric values\n",
    "train_df[numeric_cols] = train_df[numeric_cols].fillna(train_df[numeric_cols].mean())\n",
    "val_df[numeric_cols] = val_df[numeric_cols].fillna(train_df[numeric_cols].mean())\n",
    "\n",
    "# Normalize numeric columns\n",
    "scaler = StandardScaler()\n",
    "train_df[numeric_cols] = scaler.fit_transform(train_df[numeric_cols])\n",
    "val_df[numeric_cols] = scaler.transform(val_df[numeric_cols])\n",
    "\n",
    "print(\"‚úÖ Preprocessing successful!\")\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Val shape:\", val_df.shape)\n",
    "print(\"Numeric columns used:\", numeric_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af629c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# üì¶ Step 2 ‚Äî Custom Dataset (Final)\n",
    "# ========================================\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "\n",
    "class AftershootDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, numeric_cols, is_train=True):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.numeric_cols = numeric_cols\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, f\"{row['id_global']}.tif\")\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        metadata = torch.tensor(row[self.numeric_cols].values, dtype=torch.float32)\n",
    "        \n",
    "        if self.is_train:\n",
    "            label = torch.tensor([row['Temperature'], row['Tint']], dtype=torch.float32)\n",
    "            return image, metadata, label\n",
    "        else:\n",
    "            return image, metadata, row['id_global']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "317af1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataloader ready ‚Äî batches: 159\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# üß© Step 3 ‚Äî Create Train + Validation Datasets\n",
    "# ========================================\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = AftershootDataset(train_df, TRAIN_IMG_DIR, numeric_cols, is_train=True)\n",
    "val_dataset = AftershootDataset(val_df, VAL_IMG_DIR, numeric_cols, is_train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "print(\"‚úÖ Dataloader ready ‚Äî batches:\", len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc0d99b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# üß† Step 4 ‚Äî Hybrid Model Definition\n",
    "# ========================================\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class AftershootModel(nn.Module):\n",
    "    def __init__(self, metadata_dim):\n",
    "        super(AftershootModel, self).__init__()\n",
    "        \n",
    "        # CNN backbone (ResNet18)\n",
    "        self.cnn = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.cnn.fc = nn.Identity()  # Remove classifier layer\n",
    "        \n",
    "        # MLP for metadata\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(metadata_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Fusion + output layer\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 + 64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)  # Predict Temperature and Tint\n",
    "        )\n",
    "    \n",
    "    def forward(self, img, meta):\n",
    "        img_feat = self.cnn(img)\n",
    "        meta_feat = self.mlp(meta)\n",
    "        combined = torch.cat([img_feat, meta_feat], dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "173c0144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All numeric columns cleaned and converted to float.\n",
      "grayscale         float64\n",
      "aperture          float64\n",
      "flashFired        float64\n",
      "focalLength       float64\n",
      "isoSpeedRating    float64\n",
      "shutterSpeed      float64\n",
      "currTemp          float64\n",
      "currTint          float64\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satya\\AppData\\Local\\Temp\\ipykernel_9276\\2258300746.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# üßπ Fix Mixed Data Types in Numeric Columns\n",
    "# ========================================\n",
    "\n",
    "def clean_numeric(df, cols):\n",
    "    for col in cols:\n",
    "        # Convert all values to numeric (invalid ones become NaN)\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        # Fill NaN with column mean\n",
    "        df[col].fillna(df[col].mean(), inplace=True)\n",
    "    return df\n",
    "\n",
    "train_df = clean_numeric(train_df, numeric_cols)\n",
    "val_df = clean_numeric(val_df, numeric_cols)\n",
    "\n",
    "print(\"‚úÖ All numeric columns cleaned and converted to float.\")\n",
    "print(train_df[numeric_cols].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64983bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# üì¶ Step 2 ‚Äî Safe Dataset (handles all float conversions)\n",
    "# ========================================\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class AftershootDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, numeric_cols, is_train=True):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.numeric_cols = numeric_cols\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, f\"{row['id_global']}.tif\")\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        # Convert metadata safely to float32 tensor\n",
    "        metadata = np.array(row[self.numeric_cols].astype(float).values, dtype=np.float32)\n",
    "        metadata = torch.tensor(metadata, dtype=torch.float32)\n",
    "        \n",
    "        if self.is_train:\n",
    "            label = torch.tensor([float(row['Temperature']), float(row['Tint'])], dtype=torch.float32)\n",
    "            return image, metadata, label\n",
    "        else:\n",
    "            return image, metadata, row['id_global']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7603493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Safe DataLoader ready ‚Äî batches: 159\n"
     ]
    }
   ],
   "source": [
    "train_dataset = AftershootDataset(train_df, TRAIN_IMG_DIR, numeric_cols, is_train=True)\n",
    "val_dataset = AftershootDataset(val_df, VAL_IMG_DIR, numeric_cols, is_train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "print(\"‚úÖ Safe DataLoader ready ‚Äî batches:\", len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0954c31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [06:18<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] ‚Äî Loss: 2510.0388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:34<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] ‚Äî Loss: 2468.8793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:33<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] ‚Äî Loss: 2355.7002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:39<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] ‚Äî Loss: 2132.9934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:25<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] ‚Äî Loss: 1749.0506\n",
      "‚úÖ Model trained & saved successfully!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"‚úÖ Using device:\", device)\n",
    "\n",
    "model = AftershootModel(metadata_dim=len(numeric_cols)).to(device)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for img, meta, label in tqdm(train_loader):\n",
    "        img, meta, label = img.to(device), meta.to(device), label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(img, meta)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] ‚Äî Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"aftershoot_model.pth\")\n",
    "print(\"‚úÖ Model trained & saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51a8ec64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [00:27<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Predictions saved successfully at:\n",
      "C:\\Users\\satya\\Downloads\\Aftershoot_AI_Challenge\\task\\submissions\\predictions.csv\n",
      "Total predictions generated: 493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# üßæ Step 6 ‚Äî Inference (Generate Predictions)\n",
    "# ========================================\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load trained model weights\n",
    "model = AftershootModel(metadata_dim=len(numeric_cols)).to(device)\n",
    "model.load_state_dict(torch.load(\"aftershoot_model.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Create validation DataLoader\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, meta, ids in tqdm(val_loader):\n",
    "        img, meta = img.to(device), meta.to(device)\n",
    "        outputs = model(img, meta)\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        \n",
    "        for i, id_ in enumerate(ids):\n",
    "            temp, tint = outputs[i]\n",
    "            predictions.append([id_, round(float(temp)), round(float(tint))])\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "pred_df = pd.DataFrame(predictions, columns=['id_global', 'Temperature', 'Tint'])\n",
    "output_path = r\"C:\\Users\\satya\\Downloads\\Aftershoot_AI_Challenge\\task\\submissions\\predictions.csv\"\n",
    "pred_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Predictions saved successfully at:\\n{output_path}\")\n",
    "print(f\"Total predictions generated: {len(pred_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da98317d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              id_global  Temperature  Tint\n",
      "0  EB5BEE31-8D4F-450A-8BDD-27C762C75AA6         2748    11\n",
      "1  DE666E1F-0433-4958-AEC0-9A0CC0F81036         2590    10\n",
      "2  F6A6EA9C-A5C2-4BBA-9812-5CE52B818CB6         2655    11\n",
      "3  BCC39DEF-598C-491A-A3CA-14A249717F36         2532    10\n",
      "4  390ED94E-0066-4822-99B9-8F1568BDFBF5         2348     9\n",
      "Shape: (493, 3)\n"
     ]
    }
   ],
   "source": [
    "check_pred = pd.read_csv(output_path)\n",
    "print(check_pred.head())\n",
    "print(\"Shape:\", check_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f67f84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Target columns normalized successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create target scaler\n",
    "target_scaler = StandardScaler()\n",
    "\n",
    "# Fit on train targets and transform\n",
    "train_df[['Temperature', 'Tint']] = target_scaler.fit_transform(train_df[['Temperature', 'Tint']])\n",
    "\n",
    "print(\"‚úÖ Target columns normalized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e79879e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [00:24<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Predictions saved successfully at:\n",
      "C:\\Users\\satya\\Downloads\\Aftershoot_AI_Challenge\\task\\submissions\\predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# üßæ Step 6 ‚Äî Inference (with inverse scaling)\n",
    "# ========================================\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load trained model\n",
    "model = AftershootModel(metadata_dim=len(numeric_cols)).to(device)\n",
    "model.load_state_dict(torch.load(\"aftershoot_model.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, meta, ids in tqdm(val_loader):\n",
    "        img, meta = img.to(device), meta.to(device)\n",
    "        outputs = model(img, meta)\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        \n",
    "        # inverse-transform normalized outputs\n",
    "        outputs = target_scaler.inverse_transform(outputs)\n",
    "\n",
    "        for i, id_ in enumerate(ids):\n",
    "            temp, tint = outputs[i]\n",
    "            predictions.append([id_, round(float(temp)), round(float(tint))])\n",
    "\n",
    "# Save predictions\n",
    "output_path = r\"C:\\Users\\satya\\Downloads\\Aftershoot_AI_Challenge\\task\\submissions\\predictions.csv\"\n",
    "pd.DataFrame(predictions, columns=['id_global', 'Temperature', 'Tint']).to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Predictions saved successfully at:\\n{output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5a93a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:53<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] ‚Äî Loss: 0.5475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [06:16<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] ‚Äî Loss: 0.4188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:53<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] ‚Äî Loss: 0.3371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [06:00<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] ‚Äî Loss: 0.2920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:37<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] ‚Äî Loss: 0.2649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:34<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] ‚Äî Loss: 0.2482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:36<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] ‚Äî Loss: 0.2207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:36<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] ‚Äî Loss: 0.2124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:38<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] ‚Äî Loss: 0.2052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:34<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] ‚Äî Loss: 0.1957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:32<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] ‚Äî Loss: 0.1921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:34<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] ‚Äî Loss: 0.1848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:32<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] ‚Äî Loss: 0.1807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:33<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] ‚Äî Loss: 0.1711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:34<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] ‚Äî Loss: 0.1685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:32<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] ‚Äî Loss: 0.1655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:31<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] ‚Äî Loss: 0.1663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:32<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] ‚Äî Loss: 0.1607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:32<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] ‚Äî Loss: 0.1544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159/159 [05:37<00:00,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] ‚Äî Loss: 0.1502\n",
      "‚úÖ Model retrained & saved successfully (improved version)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# üöÄ Step 5 ‚Äî Improved Training Configuration\n",
    "# ========================================\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = AftershootModel(metadata_dim=len(numeric_cols)).to(device)\n",
    "\n",
    "criterion = nn.L1Loss()  # MAE\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5)  # smaller LR\n",
    "\n",
    "EPOCHS = 20  # increased training duration\n",
    "\n",
    "print(f\"‚úÖ Using device: {device}\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for img, meta, label in tqdm(train_loader):\n",
    "        img, meta, label = img.to(device), meta.to(device), label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(img, meta)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] ‚Äî Loss: {avg_loss:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"aftershoot_model.pth\")\n",
    "print(\"‚úÖ Model retrained & saved successfully (improved version)!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c57ecab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running inference with correct scaling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [00:25<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final predictions saved at:\n",
      "C:\\Users\\satya\\Downloads\\Aftershoot_AI_Challenge\\task\\submissions\\predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ‚úÖ Load original training CSV (not preprocessed)\n",
    "train_df = pd.read_csv(r\"C:\\Users\\satya\\Downloads\\Aftershoot_AI_Challenge\\task\\dataset\\Train\\sliders.csv\")\n",
    "\n",
    "# Fit scaler on actual Temperature/Tint columns (real values, not normalized)\n",
    "target_scaler = StandardScaler()\n",
    "target_scaler.fit(train_df[['Temperature', 'Tint']])\n",
    "\n",
    "# Reload trained model\n",
    "model = AftershootModel(metadata_dim=len(numeric_cols)).to(device)\n",
    "model.load_state_dict(torch.load(\"aftershoot_model.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "predictions = []\n",
    "print(\"üöÄ Running inference with correct scaling...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, meta, ids in tqdm(val_loader):\n",
    "        img, meta = img.to(device), meta.to(device)\n",
    "        outputs = model(img, meta)\n",
    "        outputs = outputs.cpu().numpy()\n",
    "\n",
    "        # Inverse scale properly using original target range\n",
    "        outputs = target_scaler.inverse_transform(outputs)\n",
    "\n",
    "        for i, id_ in enumerate(ids):\n",
    "            temp, tint = outputs[i]\n",
    "            predictions.append([id_, round(float(temp)), round(float(tint))])\n",
    "\n",
    "# Save final predictions\n",
    "output_path = r\"C:\\Users\\satya\\Downloads\\Aftershoot_AI_Challenge\\task\\submissions\\predictions.csv\"\n",
    "pd.DataFrame(predictions, columns=['id_global', 'Temperature', 'Tint']).to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Final predictions saved at:\\n{output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc6d01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
